{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691805b6-8d5a-4e49-8bb9-a0790d1fda41",
   "metadata": {},
   "source": [
    "# Real Estate Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4a287-5a07-4c0d-91ca-1c43ec1d6c86",
   "metadata": {},
   "source": [
    "This is a starter Notebook to download the dataset for your project and give some guidance in connecting to Nvidia GPU-powered models.\n",
    "\n",
    "Make sure to copy or rename this notebook to avoid accidentally overwriting it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98345c01-8c6b-43ba-9d16-32b8783b16a6",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959d054-fe43-4c68-9a49-069c2262123a",
   "metadata": {},
   "source": [
    "To install libraries you wish to use, type `!pip install <package>`\n",
    "\n",
    "For instance, to install `pandas`, type `!pip install pandas`.\n",
    "\n",
    "Below are some examples of libraries you may need, the code is commented out. Remove the `#` to execute. Uncomment one line at a time, to install the libraries one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a336794f-42ae-485e-bbfe-9195e7d7da77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install langchain_nvidia_ai_endpoints\n",
    "# !pip install googledriver\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0116c062-42eb-41d5-848f-00df141428c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googledriver import download_folder\n",
    "from openai import OpenAI\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings, NVIDIARerank\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c9213-8415-4e41-b9cf-4355b5d78302",
   "metadata": {},
   "source": [
    "## Download the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47fc50-64ef-4d7e-af9e-934432513d6f",
   "metadata": {},
   "source": [
    "The code below will download the relevant data for the Real Estate project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3164d189-fd31-4694-ab85-71ea1ac1860c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['real_estate/Consumer_Price_Index.csv',\n",
       " 'real_estate/EIBOR_2015_2024.csv',\n",
       " 'real_estate/Gdp_Quarterly.csv',\n",
       " 'real_estate/Gross_Domestic_Product_At_Constant_Prices.csv',\n",
       " 'real_estate/Transactions_test.csv',\n",
       " 'real_estate/Transactions_Training.csv']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google Drive location\n",
    "URL = \"https://drive.google.com/drive/folders/1VVLonRYyGHAWxVuPCZei4CV4oxXUKTRM?usp=drive_link\"\n",
    "\n",
    "# Download Google Drive folder\n",
    "download_folder(URL, 'real_estate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256394ff-8425-4d14-8f6f-068a8656aba5",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e8bb5-567c-4605-8731-5f758f0e0849",
   "metadata": {},
   "source": [
    "### Option 1: Pre-Deployed Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7b310-e511-4621-80aa-1a2ac50b3f50",
   "metadata": {},
   "source": [
    "This section shows how to connect to models that have been deployed on prem for, available for you to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36162a2-ed91-4afb-93a1-9ea3c6806508",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da3ead63-91a7-45dd-b5cc-6dd1900abbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short poem:\n",
      "\n",
      "The sunset fades to night\n",
      "A fiery sky, a gentle light\n",
      "The stars appear, one by one\n",
      "A diamond show, just begun\n",
      "\n",
      "The world is hushed, a peaceful sight\n",
      "The moon glows bright, with silvery light\n",
      "The night air whispers, a soothing breeze\n",
      "A calm descends, a peaceful ease\n",
      "\n",
      "I hope you enjoy it! Is there a specific theme or subject you'd like me to write about?"
     ]
    }
   ],
   "source": [
    "# Define LLM parameters for model LLama 3.1 8b\n",
    "llm = ChatNVIDIA(\n",
    "    base_url=\"http://nvpoc.ddnsfree.com:9901/v1\",\n",
    "    api_key=\"n/a\",\n",
    "    model=\"meta/llama-3.1-8b-instruct\"\n",
    ")\n",
    "\n",
    "# Create generator object\n",
    "events = llm.stream(\"Hi, write a short poem\")\n",
    "\n",
    "# Print elements of object\n",
    "for e in events:\n",
    "    print(e.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7434594-7411-4b70-bdd3-2becb4d2cf0e",
   "metadata": {},
   "source": [
    "#### Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83a1ba25-5f6f-44bc-832d-345a4b9db215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = NVIDIAEmbeddings(\n",
    "    base_url=\"http://nvpoc.ddnsfree.com:9902/v1\", \n",
    "    model=\"nvidia/nv-embedqa-e5-v5\",\n",
    "    truncate=\"END\"\n",
    ")\n",
    "\n",
    "# This will return the vector embeddings for the word 'Hi'\n",
    "# embeddings.embed_query(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e02d4-0c54-41a9-be32-66aaed5517be",
   "metadata": {},
   "source": [
    "#### Re-Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ef0849-edbc-4b5c-a9e5-355b25e036af",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = NVIDIARerank(\n",
    "    base_url=\"http://nvpoc.ddnsfree.com:9903/v1\", \n",
    "    model=\"nvidia/nv-rerankqa-mistral-4b-v3\",\n",
    "    truncate=\"END\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa56bc1e-ab63-4846-a878-1edaa93fcceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  8.8359375\n",
      "Passage:  Accelerated servers with H100 deliver the compute power—along with 3 terabytes per second (TB/s) of memory bandwidth per GPU and scalability with NVLink and NVSwitch™. \n",
      "\n",
      "Score:  0.29736328125\n",
      "Passage:  The Hopper GPU is paired with the Grace CPU using NVIDIA's ultra-fast chip-to-chip interconnect, delivering 900GB/s of bandwidth, 7X faster than PCIe Gen5. This innovative design will deliver up to 30X higher aggregate system memory bandwidth to the GPU compared to today's fastest servers and up to 10X higher performance for applications running terabytes of data. \n",
      "\n",
      "Score:  -0.10614013671875\n",
      "Passage:  A100 provides up to 20X higher performance over the prior generation and can be partitioned into seven GPU instances to dynamically adjust to shifting demands. The A100 80GB debuts the world's fastest memory bandwidth at over 2 terabytes per second (TB/s) to run the largest models and datasets. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of using a re-ranker to rank passages by relevance to a query\n",
    "query = \"What is the GPU memory bandwidth of H100 SXM?\"\n",
    "passages = [\n",
    "    \"The Hopper GPU is paired with the Grace CPU using NVIDIA's ultra-fast chip-to-chip interconnect, delivering 900GB/s of bandwidth, 7X faster than PCIe Gen5. This innovative design will deliver up to 30X higher aggregate system memory bandwidth to the GPU compared to today's fastest servers and up to 10X higher performance for applications running terabytes of data.\", \n",
    "    \"A100 provides up to 20X higher performance over the prior generation and can be partitioned into seven GPU instances to dynamically adjust to shifting demands. The A100 80GB debuts the world's fastest memory bandwidth at over 2 terabytes per second (TB/s) to run the largest models and datasets.\", \n",
    "    \"Accelerated servers with H100 deliver the compute power—along with 3 terabytes per second (TB/s) of memory bandwidth per GPU and scalability with NVLink and NVSwitch™.\", \n",
    "]\n",
    "\n",
    "# Define Re-ranker\n",
    "response = reranker.compress_documents(\n",
    "  query=query,\n",
    "  documents=[Document(page_content=passage) for passage in passages]\n",
    ")\n",
    "\n",
    "# Print Ranked Responses\n",
    "for x in response:\n",
    "    print(\"Score: \", x.metadata.get('relevance_score'))\n",
    "    print(\"Passage: \", x.page_content, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af71a20-64ad-4352-89b1-7c89cacf03ac",
   "metadata": {},
   "source": [
    "### Option 2: API Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ec240-d52f-4097-873f-7c218e140528",
   "metadata": {},
   "source": [
    "If you would like to use other Nvidia models, feel free to browse their catalog \n",
    "https://build.nvidia.com/explore/discover\n",
    "\n",
    "You will first need to create a Developer account with them. If you use your ADCB email address, you will be eligible for 5000 free credits. Otherwise, you will be given 1000 free credits. These will be consumed as you query the API.\n",
    "\n",
    "From the catalog, you can insert Python the code snippet (sample shown below). Just make sure to replace `my_api_key` with your own and `model` with the one you wish to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38fba1f3-aea9-4c40-be01-eb2f77e650fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate API key from the Nvidia catalog site\n",
    "my_api_key = 'INSERT YOUR API KEY HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a6964a8-67a1-4c84-a96b-bfe020056432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a limerick about GPU computing:\n",
      "\n",
      "There once was a GPU so fine,\n",
      "Whose computing power was truly divine.\n",
      "It processed with speed,\n",
      "And calculations with ease,\n",
      "And made complex tasks truly sublime."
     ]
    }
   ],
   "source": [
    "# Define LLM paramters\n",
    "client = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.2-3b-instruct\",\n",
    "  api_key=my_api_key, \n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "\n",
    "# Print out reponse to a query\n",
    "for chunk in client.stream([{\"role\":\"user\",\n",
    "                             \"content\":\"Write a limerick about the wonders of GPU computing.\"}]): \n",
    "  print(chunk.content, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439310d-8796-4631-9c9d-1fc0fa71a0ac",
   "metadata": {},
   "source": [
    "## Test Data for Scoring your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42edb283-272c-4a37-ac68-e8065817e58d",
   "metadata": {},
   "source": [
    "After 2:30pm, the test data will be made available. This is to allow you to evaluate your model performance against unseen data. Running the block of code below, will save down to a new folder called `real_estate_test`. This will contain the orginal data, as well as the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad0964b-dea7-450e-94cd-2e3c4ab9c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive location\n",
    "URL = \"https://drive.google.com/drive/folders/1VVLonRYyGHAWxVuPCZei4CV4oxXUKTRM?usp=drive_link\"\n",
    "\n",
    "# Download Google Drive folder\n",
    "download_folder(URL, 'real_estate_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758228af-bde9-4c2f-bbac-6be4bdd51857",
   "metadata": {},
   "source": [
    "This will only contain the test data set after it has been released. If you run it before 2:30pm, you can re-run it after it has been released."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
