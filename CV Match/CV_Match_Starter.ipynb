{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691805b6-8d5a-4e49-8bb9-a0790d1fda41",
   "metadata": {},
   "source": [
    "# CV Match Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df5803c-b40d-4718-b0e7-e50007146bd1",
   "metadata": {},
   "source": [
    "This is a starter Notebook to download the dataset for your project and give some guidance in connecting to Nvidia GPU-powered models.\n",
    "\n",
    "Make sure to copy or rename this notebook to avoid accidentally overwriting it later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98345c01-8c6b-43ba-9d16-32b8783b16a6",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3959d054-fe43-4c68-9a49-069c2262123a",
   "metadata": {},
   "source": [
    "To install libraries you wish to use, type `!pip install <package>`\n",
    "\n",
    "For instance, to install `pandas`, type `!pip install pandas`.\n",
    "\n",
    "Below are some examples of libraries you may need, the code is commented out. Remove the `#` to execute. Uncomment one line at a time, to install the libraries one-by-one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a336794f-42ae-485e-bbfe-9195e7d7da77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install langchain_nvidia_ai_endpoints\n",
    "# !pip install googledriver\n",
    "# !pip install openai\n",
    "# !pip install pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0116c062-42eb-41d5-848f-00df141428c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googledriver import download_folder\n",
    "from openai import OpenAI\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings, NVIDIARerank\n",
    "from langchain_core.documents import Document\n",
    "import pymupdf4llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c9213-8415-4e41-b9cf-4355b5d78302",
   "metadata": {},
   "source": [
    "## Download the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47fc50-64ef-4d7e-af9e-934432513d6f",
   "metadata": {},
   "source": [
    "The code below will download the relevant data for the CV Match project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3164d189-fd31-4694-ab85-71ea1ac1860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Drive location\n",
    "URL = \"https://drive.google.com/drive/folders/1-i4qvBR2M1f6IgxFAUuRLmvuH79t1xFT?usp=drive_link\"\n",
    "\n",
    "# Download Google Drive folder\n",
    "download_folder(URL, 'cv_match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35ccea-56c8-4f45-88b1-a1d1891d56c8",
   "metadata": {},
   "source": [
    "## Extract Text from PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3332b8e-9f3b-45f2-8480-c92cc3911ecb",
   "metadata": {},
   "source": [
    "The following code may be useful to you in extracting textual data from the provided PDF documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "616bd90a-1779-43ae-8728-e3d94abcf753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cv_match/trainResumes/candidate_063.pdf...\n",
      "[                                        ] (0/1=======================================[========================================] (1/1]\n",
      "# Joseline Hernandez\n",
      "\n",
      "## D A T A S C I E N T I S T A N D M A C H I N E L E A N R I N G E N G I N E E R\n",
      "\n",
      "\n",
      "### Executive Profile\n",
      "\n",
      "Good understanding of Data\n",
      "Preprocessing, training and deployment of\n",
      "machine learning and deep learning\n",
      "models.. Worked on Time Series\n",
      "Forecasting, Classification and Clustering\n",
      "Problems. Hands on experience in NLP\n",
      "tools.,\n",
      "\n",
      "### Skills\n",
      "\n",
      "Python, MySQL, Natural Language\n",
      "Processing, Machine Learning, Neural\n",
      "Networks, Flask, Docker, GIT, BERT, LSTM,\n",
      "RNN, Deep Learning, AWS, RNN,\n",
      "Tensorflow, Keras, PyTorch, Numpy,\n",
      "Pandas, Glove, Lucene, Linux, Devops,\n",
      "Spacy, GPU, Data Science.\n",
      "\n",
      "### Other Activities\n",
      "\n",
      "Data Analysis with python\n",
      "Machine Learning with Python\n",
      "Machine Learning Stanford University\n",
      "\n",
      "### Projects\n",
      "\n",
      "Study of factors affecting statistical\n",
      "comparisons, such as the type of dataset,\n",
      "the method of selection of train-test data,\n",
      "and the type of ML algorithm.\n",
      "\n",
      "\n",
      "### Work Experience\n",
      "\n",
      "BrainStrom\n",
      "Machine Learning Engineer Dec 2019- till date\n",
      "\n",
      "Worked on end-to-end Question generation application from\n",
      "paragraph using BERT and GPT2 with the use of GPU, Docker, and\n",
      "Flask Framework.\n",
      "\n",
      "IBB Tech Pvt Ltd Junior\n",
      "Machine Learning Intern, Jan 2019-Nov 2019\n",
      "\n",
      "Dashboards for real-time monitoring of Sensor Data collected using\n",
      "different sensors installed inside a house.\n",
      "\n",
      "### Education\n",
      "\n",
      "B.Tech (Telecommunication) from SKN, Coimbatore in 2019\n",
      "\n",
      "\n",
      "-----\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract text from sample CV\n",
    "md_text = pymupdf4llm.to_markdown(\"cv_match/trainResumes/candidate_063.pdf\")\n",
    "print(md_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff04501-4ff0-4b85-8f69-b81c8521ec56",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e8bb5-567c-4605-8731-5f758f0e0849",
   "metadata": {},
   "source": [
    "### Option 1: Pre-Deployed Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a7b310-e511-4621-80aa-1a2ac50b3f50",
   "metadata": {},
   "source": [
    "This section shows how to connect to models that have been deployed on prem for, available for you to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36162a2-ed91-4afb-93a1-9ea3c6806508",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da3ead63-91a7-45dd-b5cc-6dd1900abbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a short poem:\n",
      "\n",
      "The sunset fades to night\n",
      "A fiery sky, a gentle light\n",
      "The stars appear, one by one\n",
      "A diamond show, just begun\n",
      "\n",
      "The world is hushed, a peaceful sight\n",
      "The moon glows bright, with silvery light\n",
      "The night air whispers, a soothing breeze\n",
      "A calm descends, a peaceful ease\n",
      "\n",
      "I hope you enjoy it! Is there a specific theme or subject you'd like me to write about?"
     ]
    }
   ],
   "source": [
    "# Define LLM parameters for model LLama 3.1 8b\n",
    "llm = ChatNVIDIA(\n",
    "    base_url=\"http://nvpoc.ddnsfree.com:9901/v1\",\n",
    "    api_key=\"n/a\",\n",
    "    model=\"meta/llama-3.1-8b-instruct\"\n",
    ")\n",
    "\n",
    "# Create generator object\n",
    "events = llm.stream(\"Hi, write a short poem\")\n",
    "\n",
    "# Print elements of object\n",
    "for e in events:\n",
    "    print(e.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7434594-7411-4b70-bdd3-2becb4d2cf0e",
   "metadata": {},
   "source": [
    "#### Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83a1ba25-5f6f-44bc-832d-345a4b9db215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = NVIDIAEmbeddings(\n",
    "    base_url=\"http://nvpoc.ddnsfree.com:9902/v1\", \n",
    "    model=\"nvidia/nv-embedqa-e5-v5\",\n",
    "    truncate=\"END\"\n",
    ")\n",
    "\n",
    "# This will return the vector embeddings for the word 'Hi'\n",
    "# embeddings.embed_query(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e02d4-0c54-41a9-be32-66aaed5517be",
   "metadata": {},
   "source": [
    "#### Re-Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ef0849-edbc-4b5c-a9e5-355b25e036af",
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = NVIDIARerank(\n",
    "    base_url=\"http://nvpoc.ddnsfree.com:9903/v1\", \n",
    "    model=\"nvidia/nv-rerankqa-mistral-4b-v3\",\n",
    "    truncate=\"END\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa56bc1e-ab63-4846-a878-1edaa93fcceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  8.8359375\n",
      "Passage:  Accelerated servers with H100 deliver the compute power—along with 3 terabytes per second (TB/s) of memory bandwidth per GPU and scalability with NVLink and NVSwitch™. \n",
      "\n",
      "Score:  0.29736328125\n",
      "Passage:  The Hopper GPU is paired with the Grace CPU using NVIDIA's ultra-fast chip-to-chip interconnect, delivering 900GB/s of bandwidth, 7X faster than PCIe Gen5. This innovative design will deliver up to 30X higher aggregate system memory bandwidth to the GPU compared to today's fastest servers and up to 10X higher performance for applications running terabytes of data. \n",
      "\n",
      "Score:  -0.10614013671875\n",
      "Passage:  A100 provides up to 20X higher performance over the prior generation and can be partitioned into seven GPU instances to dynamically adjust to shifting demands. The A100 80GB debuts the world's fastest memory bandwidth at over 2 terabytes per second (TB/s) to run the largest models and datasets. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of using a re-ranker to rank passages by relevance to a query\n",
    "query = \"What is the GPU memory bandwidth of H100 SXM?\"\n",
    "passages = [\n",
    "    \"The Hopper GPU is paired with the Grace CPU using NVIDIA's ultra-fast chip-to-chip interconnect, delivering 900GB/s of bandwidth, 7X faster than PCIe Gen5. This innovative design will deliver up to 30X higher aggregate system memory bandwidth to the GPU compared to today's fastest servers and up to 10X higher performance for applications running terabytes of data.\", \n",
    "    \"A100 provides up to 20X higher performance over the prior generation and can be partitioned into seven GPU instances to dynamically adjust to shifting demands. The A100 80GB debuts the world's fastest memory bandwidth at over 2 terabytes per second (TB/s) to run the largest models and datasets.\", \n",
    "    \"Accelerated servers with H100 deliver the compute power—along with 3 terabytes per second (TB/s) of memory bandwidth per GPU and scalability with NVLink and NVSwitch™.\", \n",
    "]\n",
    "\n",
    "# Define Re-ranker\n",
    "response = reranker.compress_documents(\n",
    "  query=query,\n",
    "  documents=[Document(page_content=passage) for passage in passages]\n",
    ")\n",
    "\n",
    "# Print Ranked Responses\n",
    "for x in response:\n",
    "    print(\"Score: \", x.metadata.get('relevance_score'))\n",
    "    print(\"Passage: \", x.page_content, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af71a20-64ad-4352-89b1-7c89cacf03ac",
   "metadata": {},
   "source": [
    "### Option 2: API Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ec240-d52f-4097-873f-7c218e140528",
   "metadata": {},
   "source": [
    "If you would like to use other Nvidia models, feel free to browse their catalog \n",
    "https://build.nvidia.com/explore/discover\n",
    "\n",
    "You will first need to create a Developer account with them. If you use your ADCB email address, you will be eligible for 5000 free credits. Otherwise, you will be given 1000 free credits. These will be consumed as you query the API.\n",
    "\n",
    "From the catalog, you can insert Python the code snippet (sample shown below). Just make sure to replace `my_api_key` with your own and `model` with the one you wish to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38fba1f3-aea9-4c40-be01-eb2f77e650fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate API key from the Nvidia catalog site\n",
    "my_api_key = 'INSERT YOUR API KEY HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a6964a8-67a1-4c84-a96b-bfe020056432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a limerick about GPU computing:\n",
      "\n",
      "There once was a GPU so fine,\n",
      "Whose computing power was truly divine.\n",
      "It processed with speed,\n",
      "And calculations with ease,\n",
      "And made complex tasks truly sublime."
     ]
    }
   ],
   "source": [
    "# Define LLM paramters\n",
    "client = ChatNVIDIA(\n",
    "  model=\"meta/llama-3.2-3b-instruct\",\n",
    "  api_key=my_api_key, \n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    ")\n",
    "\n",
    "# Print out reponse to a query\n",
    "for chunk in client.stream([{\"role\":\"user\",\n",
    "                             \"content\":\"Write a limerick about the wonders of GPU computing.\"}]): \n",
    "  print(chunk.content, end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439310d-8796-4631-9c9d-1fc0fa71a0ac",
   "metadata": {},
   "source": [
    "## Test Data for Scoring your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42edb283-272c-4a37-ac68-e8065817e58d",
   "metadata": {},
   "source": [
    "For this project, the test data is available in the folder `testResumes`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
